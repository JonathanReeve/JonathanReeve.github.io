#+title: Measuring Canonicity
#+date: 2021-10-25
#+keywords: canonicity

At a celebration of Sarah Cole's new book, /Inventing Tomorrow: H. G. Wells and the Twentieth Century/, Prof. Cole shared a Google Books Ngrams Viewer chart, showing declining appearances of Wells's name in books, compared with increasing instances of Virginia Woolf's:

[[../images/canonicity/wells-ngrams.png]]

Cole's comment in the book is that "an easy Google Books tabulation of references in its vast archive to Wells and to Woolf illustrates the story in graphic form, pinpointing the year in which the trends reverse—when references to Woolf begin to exceed those of Wells—at 1955" [[[cite:cole20_inven_h]] 29]. (Full disclosure: Prof. Cole is one of my advisors, and I worked on this book as a research assistant, so naturally I think it's wonderful.) This features into Cole's larger argument about Well's canonicity, or lack thereof, which sets the background for her work in this book.

This got me thinking whether it were possible to improve on the measurement of canonicity.

A good amount of recent research tries to tackle this problem. Several [[https://litlab.stanford.edu/pamphlets/][pamphlets of the Stanford Literary Lab]] deal with operationalizing canonicity. Pamphlet 8, "Between Canon and Corpus"; Pamphlet 11, "Canon/Archive," and Pamphlet 17 "Popularity/Prestige" [[[cite:&algee-hewitt_between_2015-1]]; [[cite:&algee2016canon]]; [[cite:&porter2018popularity]]].

Some more:

 - [[https://culturalanalytics.org/article/21599-measuring-canonicity-graduate-read-ing-lists-in-departments-of-hispanic-studies][Measuring Canonicity: Graduate Reading Lists in Departments of Hispanic Studies | Published in Journal of Cultural Analytics]]
 - [[id:bfbe6b7a-de22-470b-9146-f39afb851888][Popular and/or prestigious? measures of scholarly esteem]]

What if we were to model canonicity according to the ratio between the number of books published /by/ a given writer, and the number of books published /about/ that author? It turns out this is achievable through book metadata APIs, like that of Open Library.

Let's define canonicity $C$ as the ratio between /books authored by the writer/ $B_a$ and /books discussing the writer/ $B_d$:

$$C = \frac{B_a}{B_d}$$

To be fair, we should specify that $B_a$ is not just books or editions, but /works/. That will make sure that we're not over-counting books that have more than one edition. Thankfully, Open Library does

Open Library has URLs that look like this:

https://openlibrary.org/subjects/person:john_galsworthy_(1867-1933)

But they only return 25 results.

Books by author:

https://openlibrary.org/search?author=Joyce%2C+James%2C+1882-1941.

Author page:

https://openlibrary.org/authors/OL31827A/James_Joyce

The source file for this blog post is a

#+BEGIN_SRC python :session session-init
import requests
import json
import pandas as pd
import altair as alt
import time
#+END_SRC

#+RESULTS:

First, look up the author

https://openlibrary.org/search/authors.json?q=james+joyce

Then, Get the number of works by author:

https://openlibrary.org/search/authors.json?q=OL31827A


#+BEGIN_SRC python :results output :session session-init
def apiCall(url):
    response = requests.get(url)
    parsed = json.loads(response.text)
    return parsed

def lookupAuthor(name):
    name = name.lower().replace(' ', '+')
    url = f'https://openlibrary.org/search/authors.json?q={name}'
    parsed = apiCall(url)
    try:
      return parsed['docs'][0]['key']
    except IndexError:
      return

def numWorksByAuthorKey(authorKey):
    url = "https://openlibrary.org/search/authors.json?q=" + authorKey
    parsed = apiCall(url)
    return parsed['docs'][0]['work_count']

def numWorksByAuthor(name):
    return numWorksByAuthorKey(lookupAuthor(name))

# Find subject heading for authorKey
# https://openlibrary.org/search/subjects.json?q=James+Joyce&subject_type=person
def authorSubjectKey(name):
    url = f"https://openlibrary.org/search/subjects.json?q={name}&subject_type=person"
    parsed = apiCall(url)
    try:
        return parsed['docs'][0]['key']
    except:
        return

# https://openlibrary.org/subjects/person:john_galsworthy_(1867-1933)/works.json
def numWorksByAuthorSubjectKey(key):
    url = f"https://openlibrary.org/{key}/works.json"
    response = requests.get(url)
    parsed = json.loads(response.text)
    try:
        return parsed['work_count']
    except:
        return

def numWorksByAuthorSubject(name):
    return numWorksByAuthorSubjectKey(authorSubjectKey(name))

def canonicityRatio(name):
    """ How much is an author discussed, adjusted for how much he/she wrote? """
    ratio = numWorksByAuthorSubject(name) / numWorksByAuthor(name)
    canonicities[name] = ratio # log it
    print(f"{name}: {ratio}")
    return ratio

canonicities = {}
#+END_SRC

#+RESULTS:

#+BEGIN_SRC python :results output :session session-init
authorList = ['Joseph Conrad', 'George Bernard Shaw', 'James Joyce',
              'H. G. Wells', 'Virginia Woolf', 'H.D.', 'Katherine Mansfield',
              'T. S. Eliot', 'Max Beerbohm', 'Arnold Bennett',
              'Henry James', 'D. H. Lawrence', 'Ford Madox Ford', 'E. M. Forster']

for author in authorList:
    print(canonicityRatio(author))
    time.sleep(1)
#+END_SRC

#+RESULTS:


#+BEGIN_SRC python :results output :session session-init
del canonicities['George Bernard Shaw'] # Doesn't work.
#+END_SRC

#+RESULTS:

#+BEGIN_SRC python :results output :session session-init
canonicityRatio('John Galsworthy')

#+END_SRC

#+RESULTS:

#+BEGIN_SRC python :results output :session session-init
df = pd.DataFrame()
df['author'], df['canonicity_score'] = canonicities.keys(), canonicities.values()
df = df.sort_values('canonicity_score')
alt.Chart(df).mark_bar().encode(
  alt.X('canonicity_score'),
  alt.Y('author',
    sort=alt.EncodingSortField(field='canonicity_score'))
).save('canonicities.html')
print(df)
#+END_SRC

#+RESULTS:
